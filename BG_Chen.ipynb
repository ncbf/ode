{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import tensorflow_probability as tfp\n",
    "import tqdm\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Paper recap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "x1 and x2 are sequences generated from constrained random walks.  x1 (x2) changes with a prob per unit time of \n",
    "0.65 (0.99) by a random amount uniformly distributed between -0.5 and 0.5 (-1 and 1). The modulus of x is then \n",
    "taken to ensure a positive sequence. Initial v are randomly selected from a unif fistrbution between -1 and 1. \n",
    "\n",
    "v1 ans v2 are unif randomly selected between -1 and +1.\n",
    "\n",
    "100 temporal patterns are simulated numerically with different sequences for x1 and x2, and different inital v1 and v2. Tau goes from 0.5 to 0.8 with dt=0.1\n",
    "\n",
    "Network: 8 hidden nodes and trained on 50 of the processes. Results shown on 50 of the processes not seen during the training. Set alpha=0.01 and beta=40 000. \n",
    "\n",
    "Temporak pattern: network produces sequence v(1) ... v(T) given initial conditions v(0) and ext input x(0), ..., x(T-1) and time steps. \n",
    "\n",
    "The neural network takes as input v(i) and x(i), and computes the function dv/dt=F(v,x).\n",
    "First layer: inputs v(i) and x(i)\n",
    "Second layer: 8 hidden nodes with tanh function \n",
    "Output layr: dv/dt no activation function "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate the data "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The diff equation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "def diff_equ(t, V, x1,x2):\n",
    "    #x1, x2 =tf.split(X[tf.cast(t, tf.int32)],1)\n",
    "    v1, v2 = V \n",
    "    dv1= tf.cast(x1, tf.float64) -2*v1 + 8*v2 -tf.cast(x1, tf.float64)*v1\n",
    "    dv2= tf.cast(x2, tf.float64) -5*v1 + v2 -tf.cast(x2, tf.float64)*v2\n",
    "    dV=np.array([dv1, dv2])\n",
    "    return dV   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate x value sequences for 0... T-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_x(T):\n",
    "    #initial values \n",
    "    x1=np.absolute(np.array([np.random.uniform(low=-0.5, high=0.5)]))\n",
    "    x2=np.absolute(np.array([np.random.uniform(low=-1.0, high=1.0)]))\n",
    "    #x1=np.absolute(np.array([[np.random.uniform(low=-0.5, high=0.5)]]))\n",
    "    #x2=np.absolute(np.array([[np.random.uniform(low=-1.0, high=1.0)]]))\n",
    "    for i in range(T): \n",
    "        #generate a bernouilli according to PD\n",
    "        p1 = np.random.binomial(1,p=0.65)\n",
    "        p2 = np.random.binomial(1,p=0.99)\n",
    "        u1=np.absolute(np.array([np.random.uniform(low=-0.5, high=0.5)]))\n",
    "        u2=np.absolute(np.array([np.random.uniform(low=-1.0, high=1.0)]))\n",
    "        x1=np.append(x1, x1[-1]+p1*u1, axis=0)\n",
    "        x2=np.append(x2, x2[-1]+p2*u2, axis=0)\n",
    "    #X=np.hstack((x1,x2))\n",
    "    return x1, x2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "ename": "InvalidArgumentError",
     "evalue": "cannot compute Sub as input #1(zero-based) was expected to be a double tensor but is a float tensor [Op:Sub]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-144-0b24b0791aca>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     21\u001b[0m                                    \u001b[0mv_initial\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;31m# initial state\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m                                    \u001b[0msolution_times\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m                                    constants={'x1': x1,'x2': x2 }) # time grid to spit out solutions for\n\u001b[0m\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;31m# extract results for the state solutions v(t)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow_probability/python/math/ode/base.py\u001b[0m in \u001b[0;36msolve\u001b[0;34m(self, ode_fn, initial_time, initial_state, solution_times, jacobian_fn, jacobian_sparsity, batch_ndims, previous_solver_internal_state, constants)\u001b[0m\n\u001b[1;32m    473\u001b[0m     \u001b[0;31m# custom_gradient will complain even if there are no variables in `ode_fn`.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    474\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtf1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvariable_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_variable_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_resource\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 475\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mgradient_helper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflat_initial_state\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mflat_constants\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    476\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    477\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mabc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mabstractmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow/python/ops/custom_gradient.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *a, **k)\u001b[0m\n\u001b[1;32m    262\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    263\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 264\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_f\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    265\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    266\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow/python/ops/custom_gradient.py\u001b[0m in \u001b[0;36mdecorated\u001b[0;34m(wrapped, args, kwargs)\u001b[0m\n\u001b[1;32m    216\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    217\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 218\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0m_eager_mode_decorator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwrapped\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    219\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    220\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0m_graph_mode_decorator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwrapped\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow/python/ops/custom_gradient.py\u001b[0m in \u001b[0;36m_eager_mode_decorator\u001b[0;34m(f, args, kwargs)\u001b[0m\n\u001b[1;32m    410\u001b[0m   \u001b[0;34m\"\"\"Implement custom gradient decorator for eager mode.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    411\u001b[0m   \u001b[0;32mwith\u001b[0m \u001b[0mtape_lib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mVariableWatcher\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mvariable_watcher\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 412\u001b[0;31m     \u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    413\u001b[0m   \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    414\u001b[0m   \u001b[0mall_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow_probability/python/math/ode/base.py\u001b[0m in \u001b[0;36mgradient_helper\u001b[0;34m(*flat_initial_state_and_constants)\u001b[0m\n\u001b[1;32m    237\u001b[0m           \u001b[0mjacobian_sparsity\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mjacobian_sparsity\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    238\u001b[0m           \u001b[0mbatch_ndims\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_ndims\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 239\u001b[0;31m           \u001b[0mprevious_solver_internal_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mprevious_solver_internal_state\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    240\u001b[0m       )\n\u001b[1;32m    241\u001b[0m       results = Results(\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow_probability/python/math/ode/dormand_prince.py\u001b[0m in \u001b[0;36m_solve\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m    200\u001b[0m             \u001b[0mode_fn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mode_fn\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m             \u001b[0minitial_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minitial_state\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 202\u001b[0;31m             \u001b[0minitial_time\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minitial_time\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    203\u001b[0m         )\n\u001b[1;32m    204\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow_probability/python/math/ode/dormand_prince.py\u001b[0m in \u001b[0;36m_initialize_solver_internal_state\u001b[0;34m(self, ode_fn, initial_time, initial_state)\u001b[0m\n\u001b[1;32m    307\u001b[0m     \u001b[0mp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_prepare_common_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minitial_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minitial_time\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    308\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 309\u001b[0;31m     \u001b[0minitial_derivative\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mode_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minitial_time\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minitial_state\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    310\u001b[0m     initial_derivative = tf.nest.map_structure(tf.convert_to_tensor,\n\u001b[1;32m    311\u001b[0m                                                initial_derivative)\n",
      "\u001b[0;32m<ipython-input-108-4ff6e1a4d3d0>\u001b[0m in \u001b[0;36mdiff_equ\u001b[0;34m(t, V, x1, x2)\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0;31m#x1, x2 =tf.split(X[tf.cast(t, tf.int32)],1)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mv1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mV\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mdv1\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat64\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mv1\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m8\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mv2\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat64\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mv1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0mdv2\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat64\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mv1\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mv2\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat64\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mv2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mdV\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdv1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdv2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py\u001b[0m in \u001b[0;36mbinary_op_wrapper\u001b[0;34m(x, y)\u001b[0m\n\u001b[1;32m   1122\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1123\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1124\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1125\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1126\u001b[0m         \u001b[0;31m# Even if dispatching the op failed, the RHS may be a tensor aware\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow/python/util/dispatch.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    199\u001b[0m     \u001b[0;34m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 201\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    202\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m       \u001b[0;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py\u001b[0m in \u001b[0;36msubtract\u001b[0;34m(x, y, name)\u001b[0m\n\u001b[1;32m    524\u001b[0m \u001b[0;34m@\u001b[0m\u001b[0mdispatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_dispatch_support\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    525\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0msubtract\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 526\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mgen_math_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msub\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    527\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    528\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow/python/ops/gen_math_ops.py\u001b[0m in \u001b[0;36msub\u001b[0;34m(x, y, name)\u001b[0m\n\u001b[1;32m  10454\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0m_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m  10455\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m> 10456\u001b[0;31m       \u001b[0m_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from_not_ok_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m  10457\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_FallbackException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m  10458\u001b[0m       \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mraise_from_not_ok_status\u001b[0;34m(e, name)\u001b[0m\n\u001b[1;32m   6841\u001b[0m   \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\" name: \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6842\u001b[0m   \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6843\u001b[0;31m   \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   6844\u001b[0m   \u001b[0;31m# pylint: enable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6845\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/six.py\u001b[0m in \u001b[0;36mraise_from\u001b[0;34m(value, from_value)\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: cannot compute Sub as input #1(zero-based) was expected to be a double tensor but is a float tensor [Op:Sub]"
     ]
    }
   ],
   "source": [
    "#Regularisation para see equ.(24)\n",
    "alpha=0.01\n",
    "#Loss function paraÂ´see equ.(10)\n",
    "beta=40000\n",
    "\n",
    "ODESolver = tfp.math.ode.DormandPrince()\n",
    "\n",
    "# initial conditions and time grid\n",
    "t_initial = 0 # initial time\n",
    "t_final = 8 # final time\n",
    "n_times = 80 # number of time steps to churn out solution for\n",
    "times = np.linspace(t_initial, t_final, n_times).astype(np.float32) \n",
    "\n",
    "v1=np.array([[np.random.uniform(low=-1.0, high=1.0)]])\n",
    "v2=np.array([[np.random.uniform(low=-1.0, high=1.0)]])\n",
    "v_initial = np.array([v1, v2]).astype(np.float32) # initial state vector\n",
    "x1, x2=gen_x(n_times)\n",
    "# integrate the ODE\n",
    "results = ODESolver.solve(diff_equ, # system of ODEs (gradient function)\n",
    "                                   t_initial, # initial time\n",
    "                                   v_initial, # initial state\n",
    "                                   solution_times=times,\n",
    "                                   constants={'x1': x1,'x2': x2 }) # time grid to spit out solutions for\n",
    "\n",
    "# extract results for the state solutions v(t)\n",
    "data = tf.cast(tf.stack(results.states, axis=-1), tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.40017716,  0.83352447],\n",
       "       [ 0.41357302,  1.22561547],\n",
       "       [ 0.41357302,  2.18052766],\n",
       "       [ 0.41357302,  3.08017581],\n",
       "       [ 0.41357302,  3.33488022],\n",
       "       [ 0.91122499,  3.48516615],\n",
       "       [ 0.91122499,  3.55686108],\n",
       "       [ 0.91122499,  3.5999878 ],\n",
       "       [ 1.34796603,  4.52015351],\n",
       "       [ 1.59981833,  4.67873253],\n",
       "       [ 2.05922584,  4.8814554 ],\n",
       "       [ 2.17837711,  5.59546551],\n",
       "       [ 2.47187198,  6.58475464],\n",
       "       [ 2.64097316,  7.15772229],\n",
       "       [ 2.91951391,  7.77074589],\n",
       "       [ 3.08188081,  8.17335497],\n",
       "       [ 3.08188081,  8.26712869],\n",
       "       [ 3.08188081,  8.57724742],\n",
       "       [ 3.39790407,  9.48525215],\n",
       "       [ 3.39790407,  9.71844318],\n",
       "       [ 3.63710127,  9.7721518 ],\n",
       "       [ 4.01972621, 10.54227248],\n",
       "       [ 4.15626879, 11.18451888],\n",
       "       [ 4.34210419, 11.88488083],\n",
       "       [ 4.59986972, 12.86365679],\n",
       "       [ 4.90056325, 13.06774342],\n",
       "       [ 4.9437225 , 13.56267304],\n",
       "       [ 4.9437225 , 13.75400455],\n",
       "       [ 5.33344721, 14.14619139],\n",
       "       [ 5.33344721, 14.42229339],\n",
       "       [ 5.42196427, 14.66788294],\n",
       "       [ 5.52600172, 15.09640029],\n",
       "       [ 5.52600172, 15.84623149],\n",
       "       [ 5.56604861, 16.41179311],\n",
       "       [ 5.56604861, 17.38895762],\n",
       "       [ 5.56604861, 17.60007263],\n",
       "       [ 5.91819634, 18.34939773],\n",
       "       [ 5.95298326, 19.32833861],\n",
       "       [ 6.01879245, 19.48868188],\n",
       "       [ 6.01879245, 20.22048725],\n",
       "       [ 6.01879245, 20.82651479],\n",
       "       [ 6.01879245, 21.67078218],\n",
       "       [ 6.07094795, 21.80294797],\n",
       "       [ 6.49774199, 21.89026235],\n",
       "       [ 6.62323274, 22.54270936],\n",
       "       [ 6.62323274, 23.0053958 ],\n",
       "       [ 6.9850738 , 23.07762667],\n",
       "       [ 7.01011308, 23.97988345],\n",
       "       [ 7.49481521, 24.85237237],\n",
       "       [ 7.49481521, 25.48159927],\n",
       "       [ 7.84883338, 26.2532335 ],\n",
       "       [ 7.84883338, 27.13376743],\n",
       "       [ 7.84883338, 28.12730277],\n",
       "       [ 7.84883338, 28.41305161],\n",
       "       [ 7.92507202, 29.24026675],\n",
       "       [ 7.99193164, 29.87368477],\n",
       "       [ 8.44232609, 29.9392468 ],\n",
       "       [ 8.57133258, 30.84598762],\n",
       "       [ 9.05555213, 30.956517  ],\n",
       "       [ 9.45397729, 31.5022322 ],\n",
       "       [ 9.46084895, 31.88621825],\n",
       "       [ 9.88876132, 32.43012867],\n",
       "       [10.34444277, 32.74034084],\n",
       "       [10.34444277, 32.80220656],\n",
       "       [10.34444277, 33.45774873],\n",
       "       [10.34444277, 33.53367734],\n",
       "       [10.64191776, 33.64566874],\n",
       "       [10.64191776, 34.3466484 ],\n",
       "       [10.77048956, 34.47419291],\n",
       "       [11.08984847, 35.21472054],\n",
       "       [11.43042971, 35.61591074],\n",
       "       [11.8587202 , 35.81180791],\n",
       "       [11.8587202 , 36.22709128],\n",
       "       [11.8587202 , 36.65607421],\n",
       "       [12.14998809, 36.72388654],\n",
       "       [12.22944889, 37.44905793],\n",
       "       [12.53468558, 37.59178113],\n",
       "       [12.53468558, 38.56053755],\n",
       "       [12.61138661, 39.16335055],\n",
       "       [12.72552356, 39.68101784],\n",
       "       [13.05388418, 39.77870118]])"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update(v, dv):\n",
    "    dv1, dv2=dv\n",
    "    new_v1=v1+dv1*dt\n",
    "    new_v2=v2+dv2*dt\n",
    "    V=np.array([new_v1, new_v2])\n",
    "    return V"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# weights and biases:\n",
    "n_state = 2\n",
    "n_ext=2\n",
    "n_hidden = 8\n",
    "W1 = tf.Variable(tf.random.normal([(n_state+n_ext), n_hidden], 0, 0.1),  trainable=True)\n",
    "b1 = tf.Variable(tf.random.normal([n_hidden], 0, 0.1),  trainable=True)\n",
    "W2 = tf.Variable(tf.random.normal([n_hidden, n_state], 0, 0.1),  trainable=True)\n",
    "b2 = tf.Variable(tf.random.normal([n_state], 0, 0.1),  trainable=True)\n",
    "\n",
    "def dvdt_nn(v):    \n",
    "    #dvdt = tf.matmul(tf.tanh(tf.matmul(tf.expand_dims(v, axis=0), W1) + b1), W2) + b2\n",
    "    output=tf.matmul(tf.expand_dims(v, axis=0), W1) + b1\n",
    "    dvdt = tf.matmul(tf.math.tanh(output), W2) + b2   \n",
    "    return tf.squeeze(dvdt, axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For a given epoch: \n",
    "    Error: e=v-T where T is the target \n",
    "    Total error: 1/2 \\sum \\beta(e)^2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# choose optimizer\n",
    "optimizer = tf.keras.optimizers.Adam(lr = 1e-3)\n",
    "\n",
    "# training step: computes predictions, compute MSE between predictions and data, computes gradients and applies them to the parameters\n",
    "def training_step():\n",
    "    \n",
    "    # start the gradient tape: this records all operations in a way that gradients can be taken\n",
    "    with tf.GradientTape() as tape:\n",
    "        \n",
    "        # solve the ODE\n",
    "        predictions = tf.stack(ODESolver.solve(dvdt_nn,\n",
    "                                   t_initial,\n",
    "                                   v_initial,\n",
    "                                   solution_times=times).states, axis=-1)\n",
    "        \n",
    "        # calculate loss\n",
    "        error=data-predictions \n",
    "        loss=0.5*beta*np.linalg.norm(error)**2       \n",
    "        \n",
    "    # calculate gradients\n",
    "    gradients = tape.gradient(loss, tape.watched_variables())\n",
    "    \n",
    "    # make gradient step\n",
    "    optimizer.apply_gradients(zip(gradients, tape.watched_variables()))   \n",
    "    \n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([27, 36])"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
