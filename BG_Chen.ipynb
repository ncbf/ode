{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import tensorflow_probability as tfp\n",
    "import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def diff_equ(X, V):\n",
    "    x1, x2 = X\n",
    "    v1, v2 = V \n",
    "    dv1= x1 -2*v1 + 8*v2 -x1*v1\n",
    "    dv2= x2 -5*v1 + v2 -x2*v2\n",
    "    dV=np.array([dv1, dv2])\n",
    "    return dV\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "x1 and x2 are sequences generated from constrained random walks.  x1 (x2) changes with a prob per unit time of \n",
    "0.65 (0.99) by a random amount uniformly distributed between -0.5 and 0.5 (-1 and 1). The modulus of x is then \n",
    "taken to ensure a positive sequence. Initial v are randomly selected from a unif fistrbution between -1 and 1. \n",
    "\n",
    "v1 ans v2 are unif randomly selected between -1 and +1.\n",
    "\n",
    "100 temporal patterns are simulated numerically with different sequences for x1 and x2, and different inital v1 and v2. Tau goes from 0.5 to 0.8 with dt=0.1\n",
    "\n",
    "Network: 8 hidden nodes and trained on 50 of the processes. Results shown on 50 of the processes not seen during the training. Set alpha=0.01 and beta=40 000. \n",
    "\n",
    "Temporak pattern: network produces sequence v(1) ... v(T) given initial conditions v(0) and ext input x(0), ..., x(T-1) and time steps. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_x(N):\n",
    "    #initial values \n",
    "    x1=np.absolute(np.array([[np.random.uniform(low=-0.5, high=0.5)]]))\n",
    "    x2=np.absolute(np.array([[np.random.uniform(low=-1.0, high=1.0)]]))\n",
    "    for i in range(N): \n",
    "        #generate a bernouilli according to PD\n",
    "        p1 = np.random.binomial(1,p=0.65)\n",
    "        p2 = np.random.binomial(1,p=0.99)\n",
    "        u1=np.absolute(np.array([[np.random.uniform(low=-0.5, high=0.5)]]))\n",
    "        u2=np.absolute(np.array([[np.random.uniform(low=-1.0, high=1.0)]]))\n",
    "        x1=np.append(x1, x1[-1]+p1*u1, axis=0)\n",
    "        x2=np.append(x2, x2[-1]+p2*u2, axis=0)\n",
    "    X=np.hstack((x1,x2))\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "v1=np.array([[np.random.uniform(low=-1.0, high=1.0)]])\n",
    "v2=np.array([[np.random.uniform(low=-1.0, high=1.0)]])\n",
    "v_init=np.array([v1,v2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The neural network takes as input v(i) and x(i), and computes the function dv/dt=F(v,x).\n",
    "First layer: inputs v(i) and x(i)\n",
    "Second layer: 8 hidden nodes with tanh function \n",
    "Output layr: dv/dt no activation function "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# weights and biases:\n",
    "n_state = 2\n",
    "n_ext=2\n",
    "n_hidden = 8\n",
    "W1 = tf.Variable(tf.random.normal([(n_state+n_ext), n_hidden], 0, 0.1),  trainable=True)\n",
    "b1 = tf.Variable(tf.random.normal([n_hidden], 0, 0.1),  trainable=True)\n",
    "W2 = tf.Variable(tf.random.normal([n_hidden, n_state], 0, 0.1),  trainable=True)\n",
    "b2 = tf.Variable(tf.random.normal([n_state], 0, 0.1),  trainable=True)\n",
    "\n",
    "def dvdt_nn(v):    \n",
    "    #dvdt = tf.matmul(tf.tanh(tf.matmul(tf.expand_dims(v, axis=0), W1) + b1), W2) + b2\n",
    "    output=tf.matmul(tf.expand_dims(v, axis=0), W1) + b1\n",
    "    dvdt = tf.matmul(tf.math.tanh(output), W2) + b2   \n",
    "    return tf.squeeze(dvdt, axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For a given epoch: \n",
    "    Error: e=v-T where T is the target \n",
    "    Total error: 1/2 \\sum \\beta(e)^2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# choose optimizer\n",
    "optimizer = tf.keras.optimizers.Adam(lr = 1e-3)\n",
    "\n",
    "# training step: computes predictions, compute MSE between predictions and data, computes gradients and applies them to the parameters\n",
    "def training_step():\n",
    "    \n",
    "    # start the gradient tape: this records all operations in a way that gradients can be taken\n",
    "    with tf.GradientTape() as tape:\n",
    "        \n",
    "        # solve the ODE\n",
    "        predictions = tf.stack(ODESolver.solve(dvdt_nn,\n",
    "                                   t_initial,\n",
    "                                   v_initial,\n",
    "                                   solution_times=times).states, axis=-1)\n",
    "        \n",
    "        # calculate loss\n",
    "        loss = tf.reduce_mean(tf.math.squared_difference(predictions, data))\n",
    "        \n",
    "    # calculate gradients\n",
    "    gradients = tape.gradient(loss, tape.watched_variables())\n",
    "    \n",
    "    # make gradient step\n",
    "    optimizer.apply_gradients(zip(gradients, tape.watched_variables()))   \n",
    "    \n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update(v, dv):\n",
    "    dv1, dv2=dv\n",
    "    new_v1=v1+dv1*dt\n",
    "    new_v2=v2+dv2*dt\n",
    "    V=np.array([new_v1, new_v2])\n",
    "    return V"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
