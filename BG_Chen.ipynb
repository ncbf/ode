{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import tensorflow_probability as tfp\n",
    "import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Paper recap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "x1 and x2 are sequences generated from constrained random walks.  x1 (x2) changes with a prob per unit time of \n",
    "0.65 (0.99) by a random amount uniformly distributed between -0.5 and 0.5 (-1 and 1). The modulus of x is then \n",
    "taken to ensure a positive sequence. Initial v are randomly selected from a unif fistrbution between -1 and 1. \n",
    "\n",
    "v1 ans v2 are unif randomly selected between -1 and +1.\n",
    "\n",
    "100 temporal patterns are simulated numerically with different sequences for x1 and x2, and different inital v1 and v2. Tau goes from 0.5 to 0.8 with dt=0.1\n",
    "\n",
    "Network: 8 hidden nodes and trained on 50 of the processes. Results shown on 50 of the processes not seen during the training. Set alpha=0.01 and beta=40 000. \n",
    "\n",
    "Temporak pattern: network produces sequence v(1) ... v(T) given initial conditions v(0) and ext input x(0), ..., x(T-1) and time steps. \n",
    "\n",
    "The neural network takes as input v(i) and x(i), and computes the function dv/dt=F(v,x).\n",
    "First layer: inputs v(i) and x(i)\n",
    "Second layer: 8 hidden nodes with tanh function \n",
    "Output layr: dv/dt no activation function "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate the data "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The diff equation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def diff_equ(t, V, x1, x2):\n",
    "    #x1, x2 =tf.split(X[tf.cast(t, tf.int32)],1)\n",
    "    v1, v2 = V \n",
    "    dv1= x1[tf.dtypes.cast(tf.round(t), tf.int32)] -2*v1 + 8*v2 -x1[tf.dtypes.cast(tf.round(t), tf.int32)]*v1\n",
    "    dv2= x2[tf.dtypes.cast(tf.round(t), tf.int32)] -5*v1 + v2 -x2[tf.dtypes.cast(tf.round(t), tf.int32)]*v2\n",
    "    dV=np.array([dv1, dv2])\n",
    "    return dV   \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate x value sequences for 0... T-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_x(T):\n",
    "    #initial values \n",
    "    x1=np.absolute(np.array([np.random.uniform(low=-0.5, high=0.5)]))\n",
    "    x2=np.absolute(np.array([np.random.uniform(low=-1.0, high=1.0)]))\n",
    "    #x1=np.absolute(np.array([[np.random.uniform(low=-0.5, high=0.5)]]))\n",
    "    #x2=np.absolute(np.array([[np.random.uniform(low=-1.0, high=1.0)]]))\n",
    "    for i in range(T): \n",
    "        #generate a bernouilli according to PD\n",
    "        p1 = np.random.binomial(1,p=0.65)\n",
    "        p2 = np.random.binomial(1,p=0.99)\n",
    "        u1=np.absolute(np.array([np.random.uniform(low=-0.5, high=0.5)]))\n",
    "        u2=np.absolute(np.array([np.random.uniform(low=-1.0, high=1.0)]))\n",
    "        x1=np.append(x1, x1[-1]+p1*u1, axis=0)\n",
    "        x2=np.append(x2, x2[-1]+p2*u2, axis=0)\n",
    "    #X=np.hstack((x1,x2))\n",
    "    return x1, x2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Regularisation para see equ.(24)\n",
    "alpha=0.01\n",
    "#Loss function paraÂ´see equ.(10)\n",
    "beta=40000\n",
    "\n",
    "ODESolver = tfp.math.ode.DormandPrince()\n",
    "\n",
    "# initial conditions and time grid\n",
    "t_initial = 0 # initial time\n",
    "t_final = 8 # final time\n",
    "n_times = 80 # number of time steps to churn out solution for\n",
    "times = np.linspace(t_initial, t_final, n_times).astype(np.float32) \n",
    "\n",
    "#v1=np.array([[np.random.uniform(low=-1.0, high=1.0)]])\n",
    "#v2=np.array([[np.random.uniform(low=-1.0, high=1.0)]])\n",
    "#v_initial = np.array([v1, v2]).astype(np.float32) # initial state vector\n",
    "\n",
    "v1=np.random.uniform(low=-1.0, high=1.0)\n",
    "v2=np.random.uniform(low=-1.0, high=1.0)\n",
    "\n",
    "v_initial = np.array([v1, v2]).astype(np.float32)\n",
    "\n",
    "x1, x2=gen_x(n_times)\n",
    "# integrate the ODE\n",
    "results = ODESolver.solve(diff_equ, # system of ODEs (gradient function)\n",
    "                                   t_initial, # initial time\n",
    "                                   v_initial, # initial state\n",
    "                                   solution_times=times,\n",
    "                                   constants={'x1': x1.astype(np.float32),'x2': x2.astype(np.float32)}) # time grid to spit out solutions for\n",
    "\n",
    "# extract results for the state solutions v(t)\n",
    "data = tf.cast(tf.stack(results.states, axis=-1), tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.12609522, -0.3306193 ], dtype=float32)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v_initial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt=0.1\n",
    "def euler(v, dv):\n",
    "    dv1, dv2=dv\n",
    "    new_v1=v1+dv1*dt\n",
    "    new_v2=v2+dv2*dt\n",
    "    V=tf.stack([new_v1, new_v2])\n",
    "    return V"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# weights and biases:\n",
    "n_state = 2\n",
    "n_ext=2\n",
    "n_hidden = 8\n",
    "W1_v = tf.Variable(tf.random.normal([(n_state), n_hidden], 0, 0.1),  trainable=True)\n",
    "W1_x=  tf.Variable(tf.random.normal([(n_ext), n_hidden], 0, 0.1),  trainable=True)\n",
    "b1 = tf.Variable(tf.random.normal([n_hidden], 0, 0.1),  trainable=True)\n",
    "W2 = tf.Variable(tf.random.normal([n_hidden, n_state], 0, 0.1),  trainable=True)\n",
    "b2 = tf.Variable(tf.random.normal([n_state], 0, 0.1),  trainable=True)\n",
    "\n",
    "def dvdt_nn(t,v,x):\n",
    "    output=tf.matmul(tf.expand_dims(v, axis=0), W1_v)+tf.matmul(tf.expand_dims(x, axis=0), W1_x)+ b1\n",
    "    dvdt = tf.matmul(tf.math.tanh(output), W2) + b2   \n",
    "    return tf.squeeze(dvdt, axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For a given epoch: \n",
    "    Error: e=v-T where T is the target \n",
    "    Total error: 1/2 \\sum \\beta(e)^2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BJ step "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2,), dtype=float32, numpy=array([-0.03633432, -0.14558354], dtype=float32)>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x=np.array([x1,x2]).astype(np.float32)\n",
    "x=np.transpose(x)\n",
    "\n",
    "dvdt_nn(0, v_initial, x[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'predictions' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-30-fd2951b82103>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpredictions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'predictions' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# choose optimizer\n",
    "optimizer = tf.keras.optimizers.Adam(lr = 1e-3)\n",
    "\n",
    "# training step: computes predictions, compute MSE between predictions and data, computes gradients and applies them to the parameters\n",
    "def training_step():\n",
    "    \n",
    "    # start the gradient tape: this records all operations in a way that gradients can be taken\n",
    "    with tf.GradientTape() as tape:\n",
    "        tape.watch([W1_v, W1_x, W2, b1, b2])\n",
    "        predictions=[]\n",
    "        pred_v = v_initial\n",
    "        for i in range(len(times)):\n",
    "            net=dvdt_nn(times[i], pred_v, x[i])\n",
    "            pred_v = euler(pred_v, net)\n",
    "            predictions.append(pred_v)\n",
    "        predictions=tf.stack(predictions)\n",
    "        \n",
    "        # calculate loss\n",
    "        error=data-tf.transpose(predictions) \n",
    "        loss=tf.reduce_mean(tf.square(error))      \n",
    "        \n",
    "    # calculate gradients\n",
    "    gradients = tape.gradient(loss, tape.watched_variables())\n",
    "    \n",
    "    # make gradient step\n",
    "    optimizer.apply_gradients(zip(gradients, tape.watched_variables()))   \n",
    "    \n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/Cellar/ipython/7.8.0/libexec/vendor/lib/python3.7/site-packages/ipykernel_launcher.py:8: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fb86965cdc7d4bb2b22aec7856020719",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Optimizing', max=200.0, style=ProgressStyle(description_wâ¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-32-e4a2a9718302>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_epochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtraining_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m     \u001b[0mlosses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-31-fdb8cd34132f>\u001b[0m in \u001b[0;36mtraining_step\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m             \u001b[0mnet\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdvdt_nn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpred_v\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m             \u001b[0mpred_v\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0meuler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred_v\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m             \u001b[0mpredictions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred_v\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0mpredictions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-27-0dde8e1c2b9b>\u001b[0m in \u001b[0;36meuler\u001b[0;34m(v, dv)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mdt\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0meuler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mdv1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdv2\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdv\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mnew_v1\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mv1\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mdv1\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mdt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mnew_v2\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mv2\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mdv2\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mdt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   6936\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_index\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_limit\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6937\u001b[0m       \u001b[0;32mraise\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6938\u001b[0;31m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tensor\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   6939\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_index\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6940\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/tensorflow/python/ops/array_ops.py\u001b[0m in \u001b[0;36m_slice_helper\u001b[0;34m(tensor, slice_spec, var)\u001b[0m\n\u001b[1;32m   1011\u001b[0m         \u001b[0mellipsis_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mellipsis_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1012\u001b[0m         \u001b[0mvar\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvar\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1013\u001b[0;31m         name=name)\n\u001b[0m\u001b[1;32m   1014\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1015\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/tensorflow/python/util/dispatch.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    199\u001b[0m     \u001b[0;34m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 201\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    202\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m       \u001b[0;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/tensorflow/python/ops/array_ops.py\u001b[0m in \u001b[0;36mstrided_slice\u001b[0;34m(input_, begin, end, strides, begin_mask, end_mask, ellipsis_mask, new_axis_mask, shrink_axis_mask, var, name)\u001b[0m\n\u001b[1;32m   1183\u001b[0m       \u001b[0mellipsis_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mellipsis_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1184\u001b[0m       \u001b[0mnew_axis_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnew_axis_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1185\u001b[0;31m       shrink_axis_mask=shrink_axis_mask)\n\u001b[0m\u001b[1;32m   1186\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1187\u001b[0m   \u001b[0mparent_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/tensorflow/python/ops/gen_array_ops.py\u001b[0m in \u001b[0;36mstrided_slice\u001b[0;34m(input, begin, end, strides, begin_mask, end_mask, ellipsis_mask, new_axis_mask, shrink_axis_mask, name)\u001b[0m\n\u001b[1;32m  10315\u001b[0m         \u001b[0mtld\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mop_callbacks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbegin\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstrides\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"begin_mask\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m  10316\u001b[0m         \u001b[0mbegin_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"end_mask\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"ellipsis_mask\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mellipsis_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m> 10317\u001b[0;31m         \"new_axis_mask\", new_axis_mask, \"shrink_axis_mask\", shrink_axis_mask)\n\u001b[0m\u001b[1;32m  10318\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0m_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m  10319\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# list to keep the loss values for plotting later (to see if it's converged)\n",
    "losses = []\n",
    "\n",
    "# number of trainine epochs\n",
    "n_epochs = 200\n",
    "\n",
    "# progressbar\n",
    "pbar = tqdm.tqdm_notebook(total = n_epochs, desc = \"Optimizing\")\n",
    "pbar.set_postfix(ordered_dict={\"loss\":None}, refresh=True)\n",
    "\n",
    "# train it! loop over epochs, doing a gradient update each step\n",
    "for i in range(n_epochs):\n",
    "    \n",
    "    loss = training_step()\n",
    "    losses.append(loss.numpy())\n",
    "    \n",
    "    # update progressbar\n",
    "    pbar.update()\n",
    "    pbar.set_postfix(ordered_dict={\"loss\":loss.numpy()}, refresh=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 80), dtype=float32, numpy=\n",
       "array([[-0.12609522, -0.27173555, -0.25115174, -0.09910691,  0.10850728,\n",
       "         0.29274505,  0.42005032,  0.45026696,  0.39502618,  0.29339138,\n",
       "         0.19192702,  0.12630874,  0.11122584,  0.14027728,  0.19305354,\n",
       "         0.24505073,  0.29613233,  0.33318233,  0.3455403 ,  0.33575672,\n",
       "         0.31312114,  0.28899068,  0.27228394,  0.26679718,  0.26986635,\n",
       "         0.3067457 ,  0.35291827,  0.3819416 ,  0.38931745,  0.3794882 ,\n",
       "         0.36137876,  0.3439673 ,  0.33304894,  0.33029023,  0.33300513,\n",
       "         0.3460072 ,  0.39590383,  0.45898718,  0.50764894,  0.52997184,\n",
       "         0.52805024,  0.51150894,  0.49179623,  0.47693747,  0.4700289 ,\n",
       "         0.47250703,  0.49904707,  0.5379966 ,  0.5690656 ,  0.5852802 ,\n",
       "         0.5865511 ,  0.57853806,  0.56784916,  0.55922127,  0.5552815 ,\n",
       "         0.5829935 ,  0.64164513,  0.69462067,  0.725401  ,  0.7332347 ,\n",
       "         0.7261722 ,  0.7137735 ,  0.7032021 ,  0.6971952 ,  0.6958306 ,\n",
       "         0.70955855,  0.73060423,  0.74727404,  0.7556197 ,  0.75676364,\n",
       "         0.7538404 ,  0.7499249 ,  0.7473356 ,  0.745926  ,  0.74574506,\n",
       "         0.7528588 ,  0.76264036,  0.7701826 ,  0.7737709 ,  0.77404636],\n",
       "       [-0.3306193 , -0.16829701,  0.03246152,  0.19405375,  0.26489908,\n",
       "         0.24211709,  0.17064282,  0.05962914, -0.04231675, -0.10156912,\n",
       "        -0.1068013 , -0.06903689, -0.01138128,  0.04133286,  0.07162006,\n",
       "         0.07406513,  0.07823879,  0.06308851,  0.03631039,  0.01048886,\n",
       "        -0.00563838, -0.00901326, -0.00186049,  0.01047458,  0.02138436,\n",
       "         0.04230231,  0.04649109,  0.03166355,  0.00911798, -0.01086372,\n",
       "        -0.02220377, -0.02372262, -0.01810451, -0.00958027, -0.00590703,\n",
       "         0.0329392 ,  0.0921392 ,  0.1123657 ,  0.10291058,  0.07813716,\n",
       "         0.05248384,  0.03528513,  0.0295277 ,  0.03286866,  0.0393604 ,\n",
       "         0.05983341,  0.10035393,  0.11634556,  0.1122921 ,  0.09852517,\n",
       "         0.08352104,  0.07305608,  0.06916972,  0.07042532,  0.07438377,\n",
       "         0.13544287,  0.17153233,  0.17310126,  0.15587863,  0.13464923,\n",
       "         0.11966124,  0.11283758,  0.11293992,  0.11665765,  0.12091617,\n",
       "         0.14237657,  0.15181448,  0.1502794 ,  0.14376524,  0.13723639,\n",
       "         0.1330632 ,  0.13153914,  0.13203017,  0.13313061,  0.13447623,\n",
       "         0.14536026,  0.14943033,  0.14851941,  0.1455461 ,  0.14238575]],\n",
       "      dtype=float32)>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'predictions' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-fd2951b82103>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpredictions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'predictions' is not defined"
     ]
    }
   ],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
